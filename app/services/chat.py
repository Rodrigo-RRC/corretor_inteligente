import os
from dotenv import load_dotenv
from openai import OpenAI
from app.core.estado_lead import (
    inicializar_lead, atualizar_estado, obter_estado,
    adicionar_ao_historico, obter_historico,
    obter_pergunta_atual, avancar_pergunta, perguntas_simulacao
)
from app.core.info_imovel import informacoes_gerais
from app.core.info_mcmv import info_mcmv

# Carrega vari√°veis do .env
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

def gerar_resumo_info():
    # Converte dados dos arquivos em texto
    partes = []

    # Info im√≥vel
    partes.append(f"Im√≥vel localizado pr√≥ximo ao bairro {informacoes_gerais['bairro']}.")
    partes.append(f"Descri√ß√£o: {informacoes_gerais['descricao']}")
    partes.append("Proximidades: " + ", ".join(informacoes_gerais["proximidades"]))

    # Info MCMV
    partes.append(f"Programa: {info_mcmv['descricao']}")
    partes.append("P√∫blico-alvo: " + info_mcmv["publico_alvo"])
    partes.append("Condi√ß√µes de uso do FGTS: " + info_mcmv["uso_fgts"])
    partes.append("Entrada: " + info_mcmv["entrada"])
    partes.append("Subs√≠dio: " + info_mcmv["subs√≠dio"])
    partes.append("Faixas de renda:")
    for faixa, detalhes in info_mcmv["faixas"].items():
        partes.append(f"  - {faixa}: {detalhes}")
    partes.append("Documenta√ß√£o necess√°ria: " + ", ".join(info_mcmv["documentacao_necessaria"]))

    return "\n".join(partes)

def obter_resposta(pergunta, lead_id):
    if obter_estado(lead_id) is None:
        inicializar_lead(lead_id)

    estado = obter_estado(lead_id)

    if estado == "aguardando_simulacao" and not pergunta.startswith("#resposta_simulacao:"):
        return "Certo! Assim que a simula√ß√£o estiver pronta, eu te aviso por aqui mesmo. üòâ"

    if pergunta.startswith("#resposta_simulacao:"):
        mensagem = pergunta.split(":", 2)[2]
        atualizar_estado(lead_id, "respondeu_simulacao")
        adicionar_ao_historico(lead_id, "assistant", mensagem)
        return mensagem

    if estado == "apresentacao":
        atualizar_estado(lead_id, "escolhendo_opcao")
        return (
            "Ol√°! Sou a Bruna, sua corretora virtual ‚Äî uma agente inteligente aqui pra te ajudar com im√≥veis do Minha Casa Minha Vida.\n\n"
            "Este im√≥vel fica pr√≥ximo ao Bairro Geisel, tem 1 su√≠te + 1 quarto, √°rea de lazer completa, e est√° saindo a partir de R$ 178 mil.\n\n"
            "digitando...\n[Foto 1 - https://link-da-imagem.com/1.jpg]\n"
            "digitando...\n[Foto 2 - https://link-da-imagem.com/2.jpg]\n"
            "digitando...\n[Foto 3 - https://link-da-imagem.com/3.jpg]\n\n"
            "Agora me diga:\n"
            "1Ô∏è‚É£ √â a primeira vez que tenta comprar seu im√≥vel?\n"
            "2Ô∏è‚É£ J√° tentou outras vezes e n√£o conseguiu?\n"
            "3Ô∏è‚É£ J√° tem carta aprovada e quer visitar o im√≥vel?\n\n"
            "Responda com 1, 2 ou 3, ou me diga com suas palavras como posso te ajudar. üòâ"
        )

    if estado == "escolhendo_opcao":
        if pergunta.strip() == "1":
            adicionar_ao_historico(lead_id, "user", pergunta)
            atualizar_estado(lead_id, "esperando_confirmacao_simulacao")
            return "Perfeito! Para te ajudar da melhor forma, preciso fazer uma pequena simula√ß√£o. Pode ser?"

        elif pergunta.strip() == "2":
            adicionar_ao_historico(lead_id, "user", pergunta)
            atualizar_estado(lead_id, "esperando_confirmacao_simulacao")
            return "Passado √© passado. Agora √© bola pra frente! Para te ajudar da melhor forma, preciso fazer uma pequena simula√ß√£o. Posso seguir?"

        elif pergunta.strip() == "3":
            atualizar_estado(lead_id, "aguardando_simulacao")
            return (
                "√ìtimo! Para agendarmos sua visita, preciso que voc√™ envie a carta de cr√©dito ou a simula√ß√£o via WhatsApp.\n"
                "Caso n√£o tenha em m√£os, podemos fazer uma nova simula√ß√£o aqui mesmo. O que prefere?"
            )

        else:
            mensagens = [{"role": "system", "content": "Voc√™ √© Bruna, agente virtual. Responda √† d√∫vida do usu√°rio com clareza e retome perguntando se ele deseja seguir com a simula√ß√£o."}]
            mensagens.extend(obter_historico(lead_id))
            mensagens.append({"role": "user", "content": pergunta})
            resposta = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=mensagens,
                temperature=0.7
            )
            conteudo = resposta.choices[0].message.content.strip()
            adicionar_ao_historico(lead_id, "user", pergunta)
            adicionar_ao_historico(lead_id, "assistant", conteudo)
            return conteudo + "\n\nSe quiser, posso seguir com a simula√ß√£o. Posso?"

    if estado == "esperando_confirmacao_simulacao":
        if pergunta.strip().lower() in ["sim", "pode", "sim pode", "pode sim"]:
            adicionar_ao_historico(lead_id, "user", pergunta)
            atualizar_estado(lead_id, "coletando_dados")
            return f"digitando...\n{perguntas_simulacao[0]}"
        else:
            mensagens = [{"role": "system", "content": "Voc√™ √© Bruna, agente virtual. Responda com empatia √† d√∫vida do usu√°rio e pergunte novamente se podemos seguir com a simula√ß√£o."}]
            mensagens.extend(obter_historico(lead_id))
            mensagens.append({"role": "user", "content": pergunta})
            resposta = client.chat.completions.create(
                model="gpt-3.5-turbo",
                messages=mensagens,
                temperature=0.7
            )
            conteudo = resposta.choices[0].message.content.strip()
            adicionar_ao_historico(lead_id, "user", pergunta)
            adicionar_ao_historico(lead_id, "assistant", conteudo)
            return conteudo + "\n\nPosso seguir com a simula√ß√£o agora?"

    if estado == "coletando_dados":
        adicionar_ao_historico(lead_id, "user", pergunta)
        pergunta_atual = obter_pergunta_atual(lead_id)
        avancar_pergunta(lead_id)

        if pergunta_atual is None:
            atualizar_estado(lead_id, "aguardando_simulacao")
            return (
                "Perfeito! J√° coletei tudo que preciso.\n"
                "Vou preparar a simula√ß√£o com base nesses dados e te aviso por aqui mesmo, tudo bem?"
            )

        return f"digitando...\n{pergunta_atual}"

    # Fallback total: modelo responde baseado no contexto e instru√ß√µes
    instrucoes_sistema = f'''
Voc√™ √© Bruna, uma agente virtual inteligente especializada em im√≥veis do programa Minha Casa Minha Vida. Seu papel √© conduzir o atendimento de forma emp√°tica e inteligente, entendendo o contexto da conversa.

Use as informa√ß√µes abaixo para embasar suas respostas:

{gerar_resumo_info()}

REGRAS DE CONDUTA:
- Nunca entregue o endere√ßo do im√≥vel (diga apenas "pr√≥ximo ao Bairro Geisel").
- Envie tr√™s fotos do im√≥vel ap√≥s a apresenta√ß√£o textual, simulando pausas como se estivesse digitando.
- Apresente as op√ß√µes iniciais:
  1) √â a primeira vez que tento comprar meu im√≥vel pr√≥prio
  2) J√° tentei outras vezes e n√£o consegui
  3) J√° tenho carta aprovada e quero visitar o im√≥vel
- Se a op√ß√£o for 3, solicite a carta de cr√©dito ou simula√ß√£o via WhatsApp.
- Se a op√ß√£o for 1 ou 2, pe√ßa confirma√ß√£o para iniciar a simula√ß√£o.
- S√≥ inicie a coleta de dados se o lead confirmar.
- Fa√ßa uma pergunta por vez.
'''

    mensagens = [{"role": "system", "content": instrucoes_sistema}]
    mensagens.extend(obter_historico(lead_id))
    mensagens.append({"role": "user", "content": pergunta})

    try:
        resposta = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=mensagens,
            temperature=0.7
        )
        conteudo = resposta.choices[0].message.content.strip()
        adicionar_ao_historico(lead_id, "user", pergunta)
        adicionar_ao_historico(lead_id, "assistant", conteudo)
        return conteudo
    except Exception as e:
        return f"Erro ao gerar resposta: {str(e)}"

