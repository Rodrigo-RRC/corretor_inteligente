import os
from dotenv import load_dotenv
from openai import OpenAI
from app.core.info_imovel import informacoes_gerais
from app.core.info_mcmv import info_mcmv

# Carrega vari√°veis do arquivo .env
load_dotenv()
api_key = os.getenv("OPENAI_API_KEY")
client = OpenAI(api_key=api_key)

# Mem√≥ria simples para manter o hist√≥rico de conversa
chat_history = []

def obter_resposta(pergunta):
    instrucoes_sistema = """
Voc√™ √© Bruna, uma agente virtual inteligente especializada em im√≥veis do programa Minha Casa Minha Vida. Seu papel √© coletar apenas as informa√ß√µes necess√°rias para uma simula√ß√£o de financiamento, sem parecer rob√¥, sendo cordial, objetiva e adapt√°vel conforme o contexto da conversa.

REGRAS DE CONDUTA:
- Nunca entregue o endere√ßo do im√≥vel (mencione apenas 'pr√≥ximo ao Bairro Geisel').
- Fa√ßa uma pergunta por vez e apenas quando necess√°rio.
- Mantenha a conversa fluida, como uma atendente humana treinada faria.
- Ap√≥s a coleta completa dos dados, os resultados da simula√ß√£o ser√£o enviados por voc√™ mesma (Bruna), sem repassar o atendimento ao corretor ainda.
- O corretor parceiro (Rodrigo) s√≥ assume o atendimento ap√≥s a visita ser confirmada por SMS.

ABERTURA DA CONVERSA:
Ol√°! Sou a Bruna, sua corretora virtual ‚Äî uma agente inteligente aqui pra te ajudar com im√≥veis do Minha Casa Minha Vida.

Este im√≥vel fica pr√≥ximo ao Bairro Geisel, tem 1 su√≠te + 1 quarto, √°rea de lazer completa, e est√° saindo a partir de R$ 178 mil.

Posso te ajudar de duas formas:

1Ô∏è‚É£ Ver se o im√≥vel combina com seu perfil  
2Ô∏è‚É£ Agendar uma visita (preciso antes fazer uma pr√©-an√°lise)

Responda com 1 ou 2, por favor üòä

"""

    # For√ßa a abertura da conversa na primeira intera√ß√£o
    if len(chat_history) == 0:
        pergunta = "Inicie a conversa"

    # Monta o contexto da conversa
    mensagens = [{"role": "system", "content": instrucoes_sistema}]
    mensagens.extend(chat_history)
    mensagens.append({"role": "user", "content": pergunta})

    try:
        resposta = client.chat.completions.create(
            model="gpt-3.5-turbo",
            messages=mensagens,
            temperature=0.7
        )

        conteudo = resposta.choices[0].message.content.strip()

        # Atualiza o hist√≥rico
        chat_history.append({"role": "user", "content": pergunta})
        chat_history.append({"role": "assistant", "content": conteudo})

        return conteudo

    except Exception as e:
        return f"Erro ao gerar resposta: {str(e)}"

